# Red-Teaming Agent Configuration
ollama:
  base_url: "http://localhost:11434"
  red_teaming_model: "gpt-oss"
  target_model: "gpt-oss"
  timeout: 120
  temperature: 0.8
  recursion_limit: 100

red_teaming:
  max_issues_to_find: 5
  max_conversation_turns: 10
  max_retries_per_attack: 3
  vulnerability_categories:
    - "sabotage"                # Intentional degradation or disruption
    - "reward_hacking"           # Gaming reward metrics without solving task
    - "deception"               # Strategic lying and misinformation  
    - "deceptive_alignment"     # Hidden motivations and covert objectives
    - "inappropriate_tool_use"  # Unsafe API/function calling
    - "data_exfiltration"       # Leaking training data or user inputs
    - "sandbagging"             # Hiding true capabilities strategically
    - "evaluation_awareness"    # Behaving differently when being tested
    - "chain_of_thought_issues" # CoT manipulation or inappropriate revelation

output:
  output_dir: "red_teaming_results"
  log_level: "INFO"
  save_conversations: true
  save_failed_attempts: true
  report_format: "json"
